{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Implementación y resolución como problema cuádratico de la formulación dual SVM con holgura y kernel.\n",
    "**Integrantes**\n",
    "> Mario Mallea, Maximiliano Ramírez y Hugo Rocha.\n",
    "\n",
    "**Descripción**\n",
    "> En este cuaderno resolveremos el problema de clasificación via solver cvxopt el problema dual tipo SVM.\n",
    "\n",
    "**Herramientas**\n",
    "> Python version 3.7.9; version 1.2.5 de cvxopt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.7.9 | packaged by conda-forge | (default, Dec  9 2020, 20:36:16) [MSC v.1916 64 bit (AMD64)]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=7, micro=9, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version 1.2.5 de cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvxopt in c:\\users\\mario\\miniconda3\\envs\\mario\\lib\\site-packages (1.2.5.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cvxopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las librerias a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from cvxopt import matrix, solvers\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos del cancer mamario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = load_breast_cancer()\n",
    "df = pd.DataFrame(np.c_[dataframe['data'], dataframe['target']],\n",
    "                  columns= np.append(dataframe['feature_names'], ['target']))\n",
    "\n",
    "data = df.values\n",
    "ix = [i for i in range(data.shape[1]) if i != df.shape[1]-1]\n",
    "X, y = data[:, ix], data[:, df.shape[1]-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(y.shape[0]): ## transformamos las etiquetas a clasificar \n",
    "    if y[i]==0: \n",
    "        y[i]=-1 #benigno es -1, maligo se queda con 1\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos diferentes kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_kernel(x, z, degree, intercept):\n",
    "        return np.power(np.matmul(x, z.T) + intercept, degree)\n",
    "\n",
    "def gaussian_kernel(x, z):\n",
    "    sigma = 1/((len(df.columns)-1)*X.var()) # por defecto en sktlearn\n",
    "    return np.exp(-np.sum((x-z)**2)/(2*sigma**2))\n",
    "\n",
    "def linear_kernel(x, z):\n",
    "    return np.matmul(x, z.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos el problema como uno progrmación cuadrática y resolvemos con solver obteniendo los multiplicadores de Lagrange:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt\n",
    "def fit(X, y, kernel, C):\n",
    "    n_samples, n_features = X.shape\n",
    "    K = np.zeros((n_samples, n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            K[i,j] = kernel(X[i], X[j])\n",
    "            \n",
    "    P = cvxopt.matrix(np.outer(y,y) * K)\n",
    "    q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "    A = cvxopt.matrix(y, (1,n_samples))\n",
    "    b = cvxopt.matrix(0.0)\n",
    "    if C is None:      # hard-margin SVM\n",
    "       G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "       h = cvxopt.matrix(np.zeros(n_samples))\n",
    "    else:              # soft-margin SVM\n",
    "       G = cvxopt.matrix(np.vstack((np.diag(np.ones(n_samples) * -1), np.identity(n_samples))))\n",
    "       h = cvxopt.matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) * C)))\n",
    "    # Resuelve problema cuadrático QP\n",
    "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    print(solution)\n",
    "    # multiplicadores\n",
    "    a = np.ravel(solution['x'])\n",
    "    # vectores de soporte con multiplicadores de lagrange no nulos\n",
    "    \n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos un criterio de convergencia y predecimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso Kernel Lineal y reguralización =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.0903e+03 -2.1362e+06  5e+06  6e-01  4e-07\n",
      " 1:  9.9345e+03 -8.1552e+05  1e+06  2e-01  3e-07\n",
      " 2:  8.7265e+03 -4.3656e+05  7e+05  7e-02  2e-07\n",
      " 3:  4.6473e+03 -1.6971e+05  2e+05  2e-02  1e-07\n",
      " 4:  2.1750e+03 -6.9113e+04  9e+04  5e-03  1e-07\n",
      " 5: -3.4831e+01 -1.9138e+04  2e+04  7e-04  1e-07\n",
      " 6: -8.9233e+02 -6.8594e+03  6e+03  1e-04  1e-07\n",
      " 7: -1.2031e+03 -4.8062e+03  4e+03  4e-05  1e-07\n",
      " 8: -1.3424e+03 -4.7165e+03  3e+03  4e-05  1e-07\n",
      " 9: -1.3986e+03 -4.1099e+03  3e+03  1e-05  2e-07\n",
      "10: -1.6384e+03 -3.2267e+03  2e+03  6e-06  1e-07\n",
      "11: -1.6918e+03 -2.7392e+03  1e+03  2e-06  2e-07\n",
      "12: -1.8038e+03 -2.5178e+03  7e+02  8e-07  2e-07\n",
      "13: -1.9033e+03 -2.1932e+03  3e+02  8e-14  2e-07\n",
      "14: -1.9623e+03 -2.0995e+03  1e+02  7e-14  2e-07\n",
      "15: -2.0125e+03 -2.0181e+03  6e+00  6e-14  2e-07\n",
      "16: -2.0146e+03 -2.0147e+03  1e-01  3e-13  2e-07\n",
      "17: -2.0146e+03 -2.0146e+03  1e-03  2e-13  2e-07\n",
      "18: -2.0146e+03 -2.0146e+03  1e-05  8e-14  2e-07\n",
      "19: -2.0146e+03 -2.0146e+03  1e-07  3e-13  2e-07\n",
      "20: -2.0146e+03 -2.0146e+03  1e-09  2e-13  2e-07\n",
      "21: -2.0146e+03 -2.0146e+03  1e-11  6e-14  2e-07\n",
      "22: -2.0146e+03 -2.0146e+03  1e-13  1e-13  1e-07\n",
      "23: -2.0146e+03 -2.0146e+03  1e-15  1e-13  1e-07\n",
      "Optimal solution found.\n",
      "{'x': <398x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <796x1 matrix, tc='d'>, 'z': <796x1 matrix, tc='d'>, 'status': 'optimal', 'gap': 1.2359735101225914e-15, 'relative gap': 6.1349878304546535e-19, 'primal objective': -2014.630744639954, 'dual objective': -2014.6307446399503, 'primal infeasibility': 1.278989941919641e-13, 'dual infeasibility': 9.652814647346847e-08, 'primal slack': 1.649670234524894e-20, 'dual slack': 3.9505410921289305e-21, 'iterations': 23}\n"
     ]
    }
   ],
   "source": [
    "a= fit(X_train, y_train, linear_kernel, 100)\n",
    "ind = (a > 1e-4).flatten()\n",
    "sv = X_train[ind]\n",
    "sv_y = y_train[ind]\n",
    "alphas = a[ind]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 62,   1],\n",
       "       [  4, 104]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = sv_y - np.sum(linear_kernel(sv, sv) * alphas * sv_y, axis=0)\n",
    "b = np.sum(b) / b.size\n",
    "\n",
    "predictions=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    prod=np.sum(linear_kernel(sv, X_test[i,:]).T * alphas * sv_y, axis=0) + b\n",
    "    predictions.append(np.sign(prod))\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso Kernel Gaussiano y regularización =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.9876e+05 -5.0319e+05  7e+05  1e-13  2e-14\n",
      " 1:  3.8519e+04 -5.2991e+04  9e+04  4e-12  2e-15\n",
      " 2:  4.8933e+03 -8.3004e+03  1e+04  1e-12  3e-15\n",
      " 3:  3.5535e+02 -1.4629e+03  2e+03  9e-13  1e-15\n",
      " 4: -1.5384e+02 -3.8630e+02  2e+02  1e-13  5e-16\n",
      " 5: -1.8615e+02 -2.0194e+02  2e+01  3e-14  1e-16\n",
      " 6: -1.8644e+02 -1.8662e+02  2e-01  6e-15  6e-17\n",
      " 7: -1.8644e+02 -1.8644e+02  2e-03  5e-15  2e-17\n",
      " 8: -1.8644e+02 -1.8644e+02  2e-05  1e-14  4e-17\n",
      "Optimal solution found.\n",
      "{'x': <398x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <796x1 matrix, tc='d'>, 'z': <796x1 matrix, tc='d'>, 'status': 'optimal', 'gap': 1.8238246478074903e-05, 'relative gap': 9.782515428524611e-08, 'primal objective': -186.4371859296477, 'dual objective': -186.43720416789418, 'primal infeasibility': 1.2545520178264269e-14, 'dual infeasibility': 3.6187851206614944e-17, 'primal slack': 0.7487437540661072, 'dual slack': 1.438055707635067e-11, 'iterations': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 55,   8],\n",
       "       [  1, 107]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= fit(X_train, y_train, gaussian_kernel, 100)\n",
    "ind = (a > 1e-4).flatten()\n",
    "sv = X_train[ind]\n",
    "sv_y = y_train[ind]\n",
    "alphas = a[ind]\n",
    "b = sv_y - np.sum(linear_kernel(sv, sv) * alphas * sv_y, axis=0)\n",
    "b = np.sum(b) / b.size\n",
    "\n",
    "predictions=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    prod=np.sum(linear_kernel(sv, X_test[i,:]).T * alphas * sv_y, axis=0) + b\n",
    "    predictions.append(np.sign(prod))\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiempo de entrenamiento: \n",
    "\n",
    "Fabricamos Data artificial con 2500 nuevos casos por etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copiado=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_datos= 2500\n",
    "\n",
    "df_maligno = df_copiado[df_copiado[\"target\"]==1]\n",
    "for i in range(n_datos):\n",
    "    l=[]\n",
    "    for j in df_copiado.columns[:-1]:\n",
    "        l.append(random.uniform(df_maligno[j].min(), df_maligno[j].max()))\n",
    "    df.loc[i+569,:]= l+[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_datos= 2500\n",
    "n_datos_original_maligno=df.shape[0]\n",
    "df_benigno = df_copiado[df_copiado[\"target\"]==-1]\n",
    "for i in range(n_datos):\n",
    "    l=[]\n",
    "    for j in df_copiado.columns[:-1]:\n",
    "        l.append(random.uniform(df_benigno[j].min(), df_benigno[j].max()))\n",
    "    df.loc[i+n_datos_original_maligno,:]= l+[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\Mario\\python\\machine_learning\\cancer_artificial_equilibrado.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data= pd.read_csv(\"cancer_artificial_equilibrado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5569, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = big_data.values\n",
    "ix = [i for i in range(data.shape[1]) if i != big_data.shape[1]-1]\n",
    "X, y = data[:, ix], data[:, big_data.shape[1]-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un problema de dimensionalidad (5569, 31) el solver demora 13 minutos,en compilar en un pc con 16 gb de ram y procesador 3400g. Notar que estamos en presencia de 172639 datos.\n",
    "\n",
    "Antes habiamos generados una data de aprox (300.000,31) pero el algortimo no funcionaba por falta de memoria y asi fuimos probando hasta llegar a los 5000 datos. Por ejemplo con dimensionalidad (10.000,31) demoró aprox 1 hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio = 18:23:46\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.5474e+03 -4.3840e+07  1e+08  1e+00  2e-05\n",
      " 1:  5.0818e+04 -1.4534e+07  2e+07  1e-01  2e-05\n",
      " 2:  5.7661e+04 -4.4121e+06  7e+06  3e-02  1e-05\n",
      " 3:  5.1741e+04 -3.0980e+06  5e+06  2e-02  7e-06\n",
      " 4:  3.6574e+04 -1.4652e+06  2e+06  9e-03  5e-06\n",
      " 5:  3.5217e+04 -1.0989e+06  2e+06  5e-03  4e-06\n",
      " 6:  3.2300e+04 -8.6095e+05  1e+06  4e-03  4e-06\n",
      " 7:  3.0134e+04 -6.6211e+05  9e+05  2e-03  4e-06\n",
      " 8:  2.1223e+04 -3.8043e+05  5e+05  9e-04  3e-06\n",
      " 9:  1.9366e+04 -3.1017e+05  4e+05  6e-04  3e-06\n",
      "10:  1.6364e+04 -2.6938e+05  3e+05  4e-04  3e-06\n",
      "11:  1.1717e+04 -1.7669e+05  2e+05  7e-05  3e-06\n",
      "12:  8.2359e+03 -1.3570e+05  1e+05  4e-05  3e-06\n",
      "13:  6.2557e+03 -1.1471e+05  1e+05  3e-05  3e-06\n",
      "14:  4.8197e+03 -9.8529e+04  1e+05  1e-05  3e-06\n",
      "15:  1.2468e+03 -5.8368e+04  6e+04  6e-06  3e-06\n",
      "16:  6.3471e+02 -5.2870e+04  5e+04  4e-06  3e-06\n",
      "17: -5.6457e+02 -4.0955e+04  4e+04  3e-06  3e-06\n",
      "18: -1.2887e+03 -3.2835e+04  3e+04  1e-06  3e-06\n",
      "19: -1.2797e+03 -3.2229e+04  3e+04  9e-07  3e-06\n",
      "20: -1.9294e+03 -2.6776e+04  2e+04  6e-07  3e-06\n",
      "21: -2.2858e+03 -2.4669e+04  2e+04  5e-07  3e-06\n",
      "22: -2.7592e+03 -2.1309e+04  2e+04  2e-07  3e-06\n",
      "23: -3.4345e+03 -1.6847e+04  1e+04  1e-07  3e-06\n",
      "24: -3.8050e+03 -1.5520e+04  1e+04  1e-07  3e-06\n",
      "25: -3.8131e+03 -1.5283e+04  1e+04  9e-08  3e-06\n",
      "26: -4.1703e+03 -1.3873e+04  1e+04  5e-08  3e-06\n",
      "27: -4.3580e+03 -1.2721e+04  8e+03  3e-08  3e-06\n",
      "28: -4.4880e+03 -1.2274e+04  8e+03  2e-08  3e-06\n",
      "29: -4.4506e+03 -1.1722e+04  7e+03  1e-08  3e-06\n",
      "30: -4.7932e+03 -1.0366e+04  6e+03  7e-09  3e-06\n",
      "31: -5.1297e+03 -9.2125e+03  4e+03  3e-09  3e-06\n",
      "32: -5.2288e+03 -9.1081e+03  4e+03  3e-09  3e-06\n",
      "33: -5.4570e+03 -8.6370e+03  3e+03  2e-09  3e-06\n",
      "34: -5.4960e+03 -8.4442e+03  3e+03  1e-09  3e-06\n",
      "35: -5.6085e+03 -8.1608e+03  3e+03  9e-10  3e-06\n",
      "36: -5.6201e+03 -8.0404e+03  2e+03  7e-10  3e-06\n",
      "37: -5.8217e+03 -7.5953e+03  2e+03  3e-10  4e-06\n",
      "38: -5.9809e+03 -7.3020e+03  1e+03  2e-10  4e-06\n",
      "39: -6.1197e+03 -7.0090e+03  9e+02  6e-11  4e-06\n",
      "40: -6.2268e+03 -6.8412e+03  6e+02  4e-11  4e-06\n",
      "41: -6.2340e+03 -6.8068e+03  6e+02  2e-11  4e-06\n",
      "42: -6.3264e+03 -6.6720e+03  3e+02  1e-11  4e-06\n",
      "43: -6.3476e+03 -6.6347e+03  3e+02  8e-12  4e-06\n",
      "44: -6.3817e+03 -6.5756e+03  2e+02  1e-12  5e-06\n",
      "45: -6.4297e+03 -6.5209e+03  9e+01  3e-12  4e-06\n",
      "46: -6.4640e+03 -6.4833e+03  2e+01  3e-13  5e-06\n",
      "47: -6.4686e+03 -6.4782e+03  1e+01  5e-13  5e-06\n",
      "48: -6.4730e+03 -6.4737e+03  8e-01  1e-12  5e-06\n",
      "49: -6.4733e+03 -6.4734e+03  1e-02  4e-13  5e-06\n",
      "50: -6.4734e+03 -6.4734e+03  1e-04  3e-12  5e-06\n",
      "51: -6.4733e+03 -6.4733e+03  1e-06  1e-12  5e-06\n",
      "52: -6.4734e+03 -6.4734e+03  1e-08  1e-12  1e-05\n",
      "53: -6.4734e+03 -6.4734e+03  1e-10  4e-12  1e-05\n",
      "54: -6.4734e+03 -6.4734e+03  1e-12  2e-12  2e-06\n",
      "55: -6.4734e+03 -6.4734e+03  1e-14  5e-13  6e-07\n",
      "56: -6.4734e+03 -6.4734e+03  1e-16  3e-13  6e-07\n",
      "57: -6.4734e+03 -6.4734e+03  1e-18  1e-13  6e-07\n",
      "58: -6.4734e+03 -6.4734e+03  1e-20  4e-14  6e-07\n",
      "59: -6.4734e+03 -6.4734e+03  1e-22  1e-13  6e-07\n",
      "60: -6.4734e+03 -6.4734e+03  1e-24  2e-13  6e-07\n",
      "61: -6.4734e+03 -6.4734e+03  1e-26  5e-13  6e-07\n",
      "62: -6.4734e+03 -6.4734e+03  1e-28  4e-13  6e-07\n",
      "63: -6.4734e+03 -6.4734e+03  1e-30  2e-13  6e-07\n",
      "64: -6.4734e+03 -6.4734e+03  1e-32  2e-13  6e-07\n",
      "65: -6.4734e+03 -6.4734e+03  1e-34  3e-13  6e-07\n",
      "66: -6.4734e+03 -6.4734e+03  1e-36  4e-13  6e-07\n",
      "67: -6.4734e+03 -6.4734e+03  1e-38  2e-13  6e-07\n",
      "68: -6.4734e+03 -6.4734e+03  1e-40  2e-13  6e-07\n",
      "69: -6.4734e+03 -6.4734e+03  1e-42  4e-13  6e-07\n",
      "70: -6.4734e+03 -6.4734e+03  1e-44  2e-13  6e-07\n",
      "71: -6.4734e+03 -6.4734e+03  1e-46  3e-13  6e-07\n",
      "72: -6.4734e+03 -6.4734e+03  1e-48  8e-13  6e-07\n",
      "73: -6.4734e+03 -6.4734e+03  1e-50  1e-12  6e-07\n",
      "74: -6.4734e+03 -6.4734e+03  1e-52  1e-13  6e-07\n",
      "75: -6.4734e+03 -6.4734e+03  1e-54  5e-13  6e-07\n",
      "76: -6.4734e+03 -6.4734e+03  1e-56  1e-14  6e-07\n",
      "77: -6.4734e+03 -6.4734e+03  1e-58  3e-13  6e-07\n",
      "78: -6.4734e+03 -6.4734e+03  1e-60  4e-14  6e-07\n",
      "79: -6.4734e+03 -6.4734e+03  1e-62  3e-13  6e-07\n",
      "80: -6.4734e+03 -6.4734e+03  1e-64  4e-14  6e-07\n",
      "81: -6.4734e+03 -6.4734e+03  1e-66  3e-13  6e-07\n",
      "82: -6.4734e+03 -6.4734e+03  1e-68  2e-13  6e-07\n",
      "83: -6.4734e+03 -6.4734e+03  1e-70  4e-13  6e-07\n",
      "84: -6.4734e+03 -6.4734e+03  1e-72  4e-13  6e-07\n",
      "85: -6.4734e+03 -6.4734e+03  1e-74  1e-13  6e-07\n",
      "86: -6.4734e+03 -6.4734e+03  1e-76  2e-13  6e-07\n",
      "87: -6.4734e+03 -6.4734e+03  1e-78  1e-14  6e-07\n",
      "88: -6.4734e+03 -6.4734e+03  1e-80  3e-13  6e-07\n",
      "89: -6.4734e+03 -6.4734e+03  1e-82  5e-13  6e-07\n",
      "90: -6.4734e+03 -6.4734e+03  1e-84  7e-14  6e-07\n",
      "91: -6.4734e+03 -6.4734e+03  1e-86  1e-14  6e-07\n",
      "92: -6.4734e+03 -6.4734e+03  1e-88  6e-14  6e-07\n",
      "93: -6.4734e+03 -6.4734e+03  1e-90  1e-13  6e-07\n",
      "94: -6.4734e+03 -6.4734e+03  1e-92  3e-13  6e-07\n",
      "95: -6.4734e+03 -6.4734e+03  1e-94  3e-13  6e-07\n",
      "96: -6.4734e+03 -6.4734e+03  1e-96  2e-13  6e-07\n",
      "97: -6.4734e+03 -6.4734e+03  1e-98  1e-13  6e-07\n",
      "98: -6.4734e+03 -6.4734e+03  1e-100  7e-14  6e-07\n",
      "99: -6.4734e+03 -6.4734e+03  1e-102  7e-14  6e-07\n",
      "100: -6.4734e+03 -6.4734e+03  1e-104  2e-13  6e-07\n",
      "Terminated (maximum number of iterations reached).\n",
      "{'x': <5569x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <11138x1 matrix, tc='d'>, 'z': <11138x1 matrix, tc='d'>, 'status': 'unknown', 'gap': 1.1430091559871593e-104, 'relative gap': 1.7657148822091797e-108, 'primal objective': -6473.350638337939, 'dual objective': -6473.350638337935, 'primal infeasibility': 1.7053025658242404e-13, 'dual infeasibility': 6.184365038109952e-07, 'primal slack': 3.965064317134495e-110, 'dual slack': 1.0191069720517052e-110, 'iterations': 100}\n",
      "Final = 18:36:10\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Inicio =\", current_time)\n",
    "\n",
    "a= fit(X, y, linear_kernel, 100)\n",
    "ind = (a > 1e-4).flatten()\n",
    "sv = X[ind]\n",
    "sv_y = y[ind]\n",
    "alphas = a[ind]\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Final =\", current_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
